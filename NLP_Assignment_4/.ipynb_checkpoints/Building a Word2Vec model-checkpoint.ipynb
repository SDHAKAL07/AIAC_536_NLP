{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Word2Vec models from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Word2Vec module from Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a text corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[\"I\", \"am\", \"trying\", \"to\", \"understand\", \"Natural\", \"Language\", \"Processing\"],\n",
    "             [\"Natural\", \"Language\", \"Processing\", \"is\", \"fun\", \"to\", \"learn\"],\n",
    "             [\"There\", \"are\", \"numerous\", \"use\", \"cases\", \"of\", \"Natural\", \"Language\", \"Processing\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a basic Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the embeddings for the word \"Natural\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.6196875e-03,  3.6657380e-03,  5.1898835e-03,  5.7419385e-03,\n",
       "        7.4669183e-03, -6.1676754e-03,  1.1056137e-03,  6.0472824e-03,\n",
       "       -2.8400505e-03, -6.1735227e-03, -4.1022300e-04, -8.3689485e-03,\n",
       "       -5.6000124e-03,  7.1045388e-03,  3.3525396e-03,  7.2256695e-03,\n",
       "        6.8002474e-03,  7.5307419e-03, -3.7891543e-03, -5.6180597e-04,\n",
       "        2.3483764e-03, -4.5190323e-03,  8.3887316e-03, -9.8581640e-03,\n",
       "        6.7646410e-03,  2.9144168e-03, -4.9328315e-03,  4.3981876e-03,\n",
       "       -1.7395747e-03,  6.7113843e-03,  9.9648498e-03, -4.3624435e-03,\n",
       "       -5.9933780e-04, -5.6956373e-03,  3.8508223e-03,  2.7866268e-03,\n",
       "        6.8910765e-03,  6.1010956e-03,  9.5384968e-03,  9.2734173e-03,\n",
       "        7.8980681e-03, -6.9895042e-03, -9.1558648e-03, -3.5575271e-04,\n",
       "       -3.0998408e-03,  7.8943167e-03,  5.9385742e-03, -1.5456629e-03,\n",
       "        1.5109634e-03,  1.7900408e-03,  7.8175711e-03, -9.5101865e-03,\n",
       "       -2.0553112e-04,  3.4691966e-03, -9.3897223e-04,  8.3817719e-03,\n",
       "        9.0107834e-03,  6.5365066e-03, -7.1162102e-04,  7.7104042e-03,\n",
       "       -8.5343346e-03,  3.2071066e-03, -4.6379971e-03, -5.0889552e-03,\n",
       "        3.5896183e-03,  5.3703394e-03,  7.7695143e-03, -5.7665063e-03,\n",
       "        7.4333609e-03,  6.6254963e-03, -3.7098003e-03, -8.7456414e-03,\n",
       "        5.4374672e-03,  6.5097557e-03, -7.8755023e-04, -6.7098560e-03,\n",
       "       -7.0859254e-03, -2.4970602e-03,  5.1432536e-03, -3.6652375e-03,\n",
       "       -9.3700597e-03,  3.8267397e-03,  4.8844791e-03, -6.4285635e-03,\n",
       "        1.2085581e-03, -2.0748770e-03,  2.4403334e-05, -9.8835090e-03,\n",
       "        2.6920044e-03, -4.7501065e-03,  1.0876465e-03, -1.5762246e-03,\n",
       "        2.1966731e-03, -7.8815762e-03, -2.7171839e-03,  2.6631986e-03,\n",
       "        5.3466819e-03, -2.3915148e-03, -9.5100943e-03,  4.5058788e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"Natural\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of each word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.key_to_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a 2nd Word2Vec model restricting the vocabulary using min_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, min_count=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the embeddings for the word \"Natural\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.4563962e-05,  3.0773198e-03, -6.8126451e-03, -1.3754654e-03,\n",
       "        7.6685809e-03,  7.3464094e-03, -3.6732971e-03,  2.6427018e-03,\n",
       "       -8.3171297e-03,  6.2054861e-03, -4.6373224e-03, -3.1641065e-03,\n",
       "        9.3113566e-03,  8.7338570e-04,  7.4907029e-03, -6.0740625e-03,\n",
       "        5.1605068e-03,  9.9228229e-03, -8.4573915e-03, -5.1356913e-03,\n",
       "       -7.0648370e-03, -4.8626517e-03, -3.7785638e-03, -8.5361991e-03,\n",
       "        7.9556061e-03, -4.8439382e-03,  8.4236134e-03,  5.2625705e-03,\n",
       "       -6.5500261e-03,  3.9578713e-03,  5.4701497e-03, -7.4265362e-03,\n",
       "       -7.4057197e-03, -2.4752307e-03, -8.6257253e-03, -1.5815723e-03,\n",
       "       -4.0343284e-04,  3.2996845e-03,  1.4418805e-03, -8.8142155e-04,\n",
       "       -5.5940580e-03,  1.7303658e-03, -8.9737179e-04,  6.7936908e-03,\n",
       "        3.9735902e-03,  4.5294715e-03,  1.4343059e-03, -2.6998555e-03,\n",
       "       -4.3668128e-03, -1.0320747e-03,  1.4370275e-03, -2.6460087e-03,\n",
       "       -7.0737829e-03, -7.8053069e-03, -9.1217868e-03, -5.9351693e-03,\n",
       "       -1.8474245e-03, -4.3238713e-03, -6.4606704e-03, -3.7173224e-03,\n",
       "        4.2891586e-03, -3.7390434e-03,  8.3781751e-03,  1.5339935e-03,\n",
       "       -7.2423196e-03,  9.4337985e-03,  7.6312125e-03,  5.4932819e-03,\n",
       "       -6.8488456e-03,  5.8226790e-03,  4.0090932e-03,  5.1853694e-03,\n",
       "        4.2559016e-03,  1.9397545e-03, -3.1701624e-03,  8.3538452e-03,\n",
       "        9.6121803e-03,  3.7926030e-03, -2.8369951e-03,  7.1275235e-06,\n",
       "        1.2188185e-03, -8.4583247e-03, -8.2239453e-03, -2.3101569e-04,\n",
       "        1.2372875e-03, -5.7433806e-03, -4.7252737e-03, -7.3460746e-03,\n",
       "        8.3286157e-03,  1.2129784e-04, -4.5093987e-03,  5.7017053e-03,\n",
       "        9.1800150e-03, -4.0998720e-03,  7.9646818e-03,  5.3754342e-03,\n",
       "        5.8791232e-03,  5.1259040e-04,  8.2130842e-03, -7.0190406e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"Natural\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.key_to_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Processing', 'Language', 'Natural', 'to']\n"
     ]
    }
   ],
   "source": [
    "words = list(model.wv.key_to_index.keys())\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of each word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a 2nd Word2Vec model restricting the vocabulary using min_count and each vector of size 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, min_count=2, vector_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the embeddings for the word \"Natural\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.71075731e-03, -1.48577814e-03, -3.56119068e-04,  3.35454941e-04,\n",
       "       -6.37046469e-05,  3.82725790e-04,  2.03795359e-03, -6.75718002e-06,\n",
       "       -1.08198845e-03, -5.03576186e-04,  1.96576631e-03,  5.04700758e-04,\n",
       "       -2.41420668e-04,  3.11108236e-03, -1.64042786e-03, -2.79469881e-04,\n",
       "        3.05847055e-03,  2.24980921e-03,  5.00952010e-04, -2.96085351e-03,\n",
       "        3.82915343e-04, -7.62751908e-04,  3.12274578e-03,  4.03309270e-04,\n",
       "        4.96687891e-04,  8.02136667e-04, -6.12002215e-04, -1.66654470e-03,\n",
       "        7.74764994e-05, -6.71393471e-04,  2.20031105e-03,  2.98004108e-03,\n",
       "       -2.24918127e-04,  9.92338290e-04, -2.03588489e-03,  5.66441624e-04,\n",
       "       -2.30874424e-03, -2.89800880e-03, -1.96673442e-03, -2.98549165e-03,\n",
       "        2.42586504e-03, -1.92401046e-03,  2.75878399e-03, -2.41451501e-03,\n",
       "        1.14055828e-03,  3.22499941e-03, -2.59514921e-03, -3.31501919e-03,\n",
       "       -1.44304871e-03, -8.94376833e-04, -9.04297849e-05, -2.94385036e-03,\n",
       "       -2.87251920e-03,  9.33403557e-04, -2.73546902e-03, -3.02311219e-03,\n",
       "       -7.80155242e-04, -2.87726917e-03, -2.35221675e-03, -2.80038361e-03,\n",
       "       -1.00442965e-04, -1.52143277e-03,  2.20905826e-03,  5.09053469e-04,\n",
       "       -1.11382524e-03,  2.03632400e-03, -2.00442830e-03, -1.55205652e-03,\n",
       "       -2.40250304e-03, -1.44552672e-03, -6.03110006e-04,  2.16321438e-03,\n",
       "       -9.23464308e-04,  1.63965579e-03,  2.30148085e-03, -2.48790183e-03,\n",
       "        1.52161682e-03,  2.04232614e-03, -9.84824845e-04,  2.20834068e-03,\n",
       "        2.04195967e-03, -2.14782823e-03, -2.25485046e-03,  8.46319599e-04,\n",
       "       -5.41272981e-04, -2.02170922e-03,  3.16640292e-03, -1.71004888e-03,\n",
       "       -2.18469906e-03, -3.99617347e-05, -9.00476007e-04,  1.48133433e-04,\n",
       "       -1.17915275e-03, -1.39776865e-04, -2.36205262e-04,  2.74273567e-04,\n",
       "        2.73160567e-03, -1.91223586e-03, -5.53175982e-04,  1.85720250e-03,\n",
       "        2.72270688e-03, -1.48101093e-03,  2.99514458e-03,  2.75122165e-03,\n",
       "       -1.47840742e-03,  1.01035039e-04,  1.42483041e-03, -1.30877341e-03,\n",
       "       -1.85332180e-03, -2.17077415e-03, -2.23579409e-04, -9.86405212e-05,\n",
       "        1.48769503e-03, -8.24684685e-04, -5.75363629e-05,  8.20625224e-04,\n",
       "        1.62253296e-03, -1.02694830e-05, -2.11313646e-03, -3.08693573e-03,\n",
       "        8.88586055e-06,  2.22063134e-03,  4.88674268e-04, -2.98884069e-03,\n",
       "       -2.64620152e-03,  2.18396750e-03, -1.26189354e-03,  2.08499748e-03,\n",
       "       -2.22701067e-03,  2.82655400e-03, -2.17210804e-03,  1.09600660e-03,\n",
       "       -3.52328614e-04, -2.26250920e-03, -1.09586562e-03, -3.87137319e-04,\n",
       "       -1.82364660e-03, -4.03782527e-04, -2.52110441e-03,  8.82219872e-04,\n",
       "        3.02338274e-03, -7.92416744e-04, -3.25503352e-04,  1.17118715e-03,\n",
       "        2.88836239e-03, -1.97395077e-03, -2.29585916e-03, -9.77661577e-04,\n",
       "        3.04923207e-03,  2.88755895e-04, -2.89280014e-03, -4.82326344e-04,\n",
       "        3.15982173e-03, -2.51649576e-03, -1.78603292e-03,  3.10552074e-03,\n",
       "       -2.99124210e-03,  1.27530261e-03,  2.21813520e-04,  2.22023367e-03,\n",
       "        2.77091772e-03, -9.50261776e-04, -1.33077102e-03,  2.96597253e-03,\n",
       "        6.96548610e-04,  2.08298047e-03, -3.14857159e-03,  3.19670793e-03,\n",
       "       -4.49436106e-04, -2.01737159e-03,  9.97511554e-04, -1.52203633e-04,\n",
       "        1.56883080e-03, -7.61007075e-04, -1.37928093e-03,  7.59299612e-04,\n",
       "        2.78479466e-03, -1.66520197e-03,  8.89559567e-04, -2.66351830e-03,\n",
       "       -2.25778227e-03, -1.55889589e-04, -2.92257592e-03,  9.29812610e-04,\n",
       "        5.32865117e-04, -7.73230800e-04,  1.66793028e-03,  3.24959564e-03,\n",
       "        2.81808921e-03, -6.26741676e-04,  6.86050626e-04, -1.33456313e-03,\n",
       "       -2.74713524e-03,  2.09265202e-03, -6.49727182e-04, -2.22068236e-04,\n",
       "       -5.90444019e-04, -1.51188846e-03,  1.35390321e-03, -1.42339349e-03,\n",
       "       -3.19284876e-03,  2.98103853e-03,  1.38835632e-03,  3.07824486e-03,\n",
       "        2.21450091e-03,  9.74912255e-04,  3.26800672e-03, -1.47488038e-03,\n",
       "       -2.26777047e-03,  1.40912691e-03,  1.24300004e-03, -1.88820367e-03,\n",
       "        3.23492009e-03, -1.18610228e-03,  3.18313553e-03,  2.78242020e-04,\n",
       "       -2.11281888e-03, -6.59039011e-04, -2.45901826e-03, -9.93174268e-04,\n",
       "        3.47232417e-04,  3.16089601e-03,  3.11861583e-03, -2.19862582e-03,\n",
       "        1.15838367e-03,  7.58523529e-04, -8.29784083e-04, -3.07639083e-03,\n",
       "        3.42375424e-04, -2.72190222e-03,  2.10672966e-03, -1.93336012e-03,\n",
       "        1.84514641e-03,  3.27790785e-03, -5.33334423e-05,  1.50949752e-03,\n",
       "       -6.03133463e-04,  2.45358702e-03,  1.31336565e-03, -3.00344150e-03,\n",
       "       -7.99501315e-04,  1.20958965e-03, -3.31894553e-05, -4.00423596e-04,\n",
       "       -3.51812836e-04, -5.57200518e-04,  2.01650852e-04,  1.38836505e-03,\n",
       "       -1.41759717e-03, -1.27787387e-03, -1.76056219e-05,  8.97852588e-05,\n",
       "       -5.62687710e-05, -1.59516896e-03,  1.43780070e-03, -7.23973091e-04,\n",
       "        7.01179903e-04,  2.22174320e-04,  1.98989222e-03, -2.28079362e-03,\n",
       "       -2.27190345e-03, -1.49208587e-03,  3.14527634e-03, -5.30627556e-04,\n",
       "       -3.14308098e-03, -1.81680516e-04, -1.48297427e-03,  2.00002640e-03,\n",
       "       -3.19456169e-03,  9.53000388e-04, -3.08427727e-03,  4.16600320e-04,\n",
       "        1.99973257e-03,  2.46578245e-03, -2.54048780e-03, -2.01767450e-03,\n",
       "       -2.27948022e-03, -2.63944664e-03, -3.16636008e-03, -7.08498934e-04,\n",
       "       -2.78644176e-04, -2.41873390e-03,  2.26234552e-03,  3.73206538e-04,\n",
       "        1.94295566e-03,  4.90955485e-04,  2.63121910e-04, -2.45604315e-03,\n",
       "       -7.25552614e-04,  1.44035975e-03, -1.69510487e-03,  3.76929849e-04,\n",
       "        9.61121346e-04, -5.12120314e-04,  3.31076514e-03,  2.78321141e-03,\n",
       "        8.05222197e-04,  2.37274845e-03,  1.96381263e-03, -1.86020578e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"Natural\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "num_words = len(model.wv.key_to_index)\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of each word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a 4th Word2Vec model using 2 worker threads, skipgram approach and negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, min_count=1, vector_size=300, workers=2, sg=1, negative=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "num_words = len(model.wv.key_to_index)\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "num_words = len(model.wv.key_to_index)\n",
    "print(num_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of each word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this assignment we used few of the important python libraries that are crucial for NLP tasks. Here are the libraries we used in this assignment and thier brief description:\n",
    "# 1.Gensim\n",
    "Gensim is a popular library for topic modeling and document similarity analysis. It provides a straightforward implementation of Word2Vec. Easy-to-use API, efficient handling of large text corpora, and support for various models like Word2Vec, FastText, and Doc2Vec.\n",
    "\n",
    "### Steps Followed\n",
    "\n",
    "1. Import the Word2Vec Module:\n",
    "The necessary module for creating Word2Vec models is imported from the gensim library.\n",
    "\n",
    "2. Define a Text Corpus:\n",
    "A set of example sentences is defined to train the Word2Vec model.\n",
    "\n",
    "3. Build a Basic Word2Vec Model:\n",
    "An initial Word2Vec model is created using the defined text corpus with a minimum word count threshold.\n",
    "\n",
    "4. Visualize Word Embeddings:\n",
    "The word embeddings for a specific word (e.g., \"Natural\") are visualized to inspect the learned vector.\n",
    "\n",
    "5. Check the Size of Each Word Vector:\n",
    "The dimensionality of the word vectors in the model is examined.\n",
    "\n",
    "6. Check the Size of the Vocabulary:\n",
    "The size of the vocabulary, i.e., the number of unique words in the model, is checked.\n",
    "\n",
    "7. Build a Second Word2Vec Model with Restricted Vocabulary:\n",
    "A new Word2Vec model is built with a higher minimum word count to restrict the vocabulary size.\n",
    "\n",
    "8. Visualize the Embeddings and Vocabulary Size Again:\n",
    "The word embeddings and the vocabulary size for the new model are checked and compared with the previous model.\n",
    "\n",
    "9. Build a Word2Vec Model with Custom Vector Size:\n",
    "A Word2Vec model is built with a specified vector size (e.g., 300 dimensions).\n",
    "\n",
    "10. Build a Word2Vec Model with Additional Parameters:\n",
    "A more advanced Word2Vec model is created using parameters such as multiple worker threads, skip-gram approach, and negative sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
