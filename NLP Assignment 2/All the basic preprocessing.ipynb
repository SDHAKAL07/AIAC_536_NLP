{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0516e807",
   "metadata": {},
   "source": [
    "## All the basic preprocessing in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858374d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Leapfrog\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Leapfrog\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\Leapfrog\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bb172c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virat Kohli did a great thing to open his rest...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This place have some really heathy options to ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aerocity is the most finest place in Delhi for...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review sentiment\n",
       "0  Virat Kohli did a great thing to open his rest...  positive\n",
       "1  This place have some really heathy options to ...  positive\n",
       "2  Aerocity is the most finest place in Delhi for...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Leapfrog\\Desktop\\Others\\Mtech AI\\AIAC_536_NLP\\AIAC_536_NLP\\NLP Assignment 2\\zomato_reviews.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2635f5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Virat Kohli did a great thing to open his rest...\n",
       "1       This place have some really heathy options to ...\n",
       "2       Aerocity is the most finest place in Delhi for...\n",
       "3       Yesterday evening there was small team lunch ,...\n",
       "4       I find aerocity to be the best place in delhi ...\n",
       "                              ...                        \n",
       "1591    || DESI LANE || So we were at alipore's most h...\n",
       "1592    \"Desi Lane\" is one of the most trending place ...\n",
       "1593    One of the cool and pocket pinch restaurant at...\n",
       "1594    \"DESI LANE\" one of the best places in town and...\n",
       "1595    Looking for good place for lunch but dont wann...\n",
       "Length: 1596, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.Series(df.Review.tolist()).astype(str)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da60f4",
   "metadata": {},
   "source": [
    "## Text Cleaning (Removal of special characters/punctuations & case folding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a273892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(corpus, keep_list):\n",
    "    '''\n",
    "    Purpose : Function to keep only alphabets, digits and certain words (punctuations, qmarks, tabs etc. removed)\n",
    "    \n",
    "    Input : Takes a text corpus, 'corpus' to be cleaned along with a list of words, 'keep_list', which have to be retained\n",
    "            even after the cleaning process\n",
    "    \n",
    "    Output : Returns the cleaned text corpu\n",
    "    \n",
    "    '''\n",
    "    cleaned_corpus = pd.Series()\n",
    "    for row in corpus:\n",
    "        qs = []\n",
    "        \n",
    "        for word in row.split():\n",
    "            if word not in keep_list:\n",
    "                p1= re.sub(pattern='[^a-zA-Z0-9]', repl=' ',string=word)\n",
    "                p1 = p1.lower()\n",
    "                qs.append(p1)\n",
    "            else : qs.append(word)\n",
    "        cleaned_corpus = cleaned_corpus._append(pd.Series(' '.join(qs)))\n",
    "    return cleaned_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f647ef05",
   "metadata": {},
   "source": [
    "## Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483237e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(corpus):\n",
    "    wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']\n",
    "    stop = set(stopwords.words('english'))\n",
    "    for word in wh_words:\n",
    "        stop.remove(word)\n",
    "    corpus = [[x for x in x.split() if x not in stop] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcafc13a",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4496e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(corpus):\n",
    "    lem = WordNetLemmatizer()\n",
    "    corpus = [[lem.lemmatize(x, pos = 'v') for x in x] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd06845d",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "219a9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(corpus, stem_type =  None):\n",
    "    if stem_type == 'snowball':\n",
    "        stemmer = SnowballStemmer(language = 'english')\n",
    "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "    else:\n",
    "        stemmer = PorterStemmer()\n",
    "        corpus = [[stemmer.stem(x) for x in x] for x in corpus]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2957acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus, keep_list, cleaning = True, stemming = False, stem_type = None, lemmatization = False, remove_stopwords = True):\n",
    "    '''\n",
    "    Purpose : Function to perform all pre-processing tasks (cleaning, stemming, lemmatization, stopwords removal etc.)\n",
    "    \n",
    "    Input : \n",
    "    'corpus' - Text corpus on which pre-processing tasks will be performed\n",
    "    'keep_list' - List of words to be retained during cleaning process\n",
    "    'cleaning', 'stemming', 'lemmatization', 'remove_stopwords' - Boolean variables indicating whether a particular task should \n",
    "                                                                  be performed or not\n",
    "    'stem_type' - Choose between Porter stemmer or Snowball(Porter2) stemmer. Default is \"None\", which corresponds to Porter\n",
    "                  Stemmer. 'snowball' corresponds to Snowball Stemmer\n",
    "    \n",
    "    Note : Either stemming or lemmatization should be used. There's no benefit of using both of them together\n",
    "    \n",
    "    Output : Returns the processed text corpus\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if cleaning == True:\n",
    "        corpus = text_clean(corpus, keep_list)\n",
    "    \n",
    "    if remove_stopwords == True:\n",
    "        corpus = stopwords_removal(corpus)\n",
    "    else :\n",
    "        corpus = [[x for x in x.split()] for x in corpus]\n",
    "    \n",
    "    if lemmatization == True:\n",
    "        corpus = lemmatize(corpus)\n",
    "        \n",
    "        \n",
    "    if stemming == True:\n",
    "        corpus = stem(corpus, stem_type)\n",
    "    \n",
    "    corpus = [' '.join(x) for x in corpus]        \n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18b297fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dot_words = ['U.S.A', 'Mr.', 'Mrs.', 'D.C.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb350414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing with Lemmatization here\n",
    "corpus_with_lemmatization = preprocess(corpus, keep_list = common_dot_words, stemming = False, stem_type = None, lemmatization = True, remove_stopwords = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b4748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing with Stemming here here\n",
    "corpus_with_stemming = preprocess(corpus, keep_list = common_dot_words, stemming = True, stem_type = \"snowball\", lemmatization = False, remove_stopwords = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93a186",
   "metadata": {},
   "source": [
    "## Let's see the results on applying\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ea1c07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original string:  Virat Kohli did a great thing to open his restaurant in an exquisite place of Delhi. Wide range of food with lots and lots of options on drinks. Courteous staff with a quick response on anything.\n"
     ]
    }
   ],
   "source": [
    "print(\"Original string: \", corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7538cea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String after lemmatiization:  virat kohli great thing open restaurant exquisite place delhi wide range food lot lot options drink courteous staff quick response anything\n"
     ]
    }
   ],
   "source": [
    "print(\"String after lemmatiization: \", corpus_with_lemmatization[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e9491df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String after stemming:  virat koh great thing open restaur exquisit place delhi wide rang food lot lot option drink courteous staff quick respons anyth\n"
     ]
    }
   ],
   "source": [
    "print(\"String after stemming: \", corpus_with_stemming[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598d4aef",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
